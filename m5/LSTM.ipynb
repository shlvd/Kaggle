{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxcovPdQGDuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLISGRgmGI3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataPath = \"/kaggle/input/m5-forecasting-accuracy/\"\n",
        "timesteps = 14\n",
        "startDay = 350"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jge55ocmGI15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt = pd.read_csv(dataPath + \"/sales_train_validation.csv\")\n",
        "dt.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjcHlOfIGIyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To reduce memory usage\n",
        "def downcast_dtypes(df):\n",
        "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
        "    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n",
        "    df[float_cols] = df[float_cols].astype(np.float32)\n",
        "    df[int_cols] = df[int_cols].astype(np.int16)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNu4SHhAGIxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reduce memory usage and compare with the previous one to be sure\n",
        "dt = downcast_dtypes(dt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezUK7YS7GIuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Take the transpose so that we have one day for each row, and 30490 items' sales as columns\n",
        "dt = dt.T    \n",
        "dt.head(8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPw57PdeGIrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove id, item_id, dept_id, cat_id, store_id, state_id columns\n",
        "dt = dt[6 + startDay:]\n",
        "dt.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgxzRts0GIoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar = pd.read_csv(dataPath + \"/calendar.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDPnanxtGIml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create dataframe with zeros for 1969 days in the calendar\n",
        "daysBeforeEvent = pd.DataFrame(np.zeros((1969,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0aIkkYOGepA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"1\" is assigned to the days before the event_name_1. Since \"event_name_2\" is rare, it was not added.\n",
        "for x,y in calendar.iterrows():\n",
        "    if((pd.isnull(calendar[\"event_name_1\"][x])) == False):\n",
        "           daysBeforeEvent[0][x-1] = 1 \n",
        "            #if first day was an event this row will cause an exception because \"x-1\".\n",
        "            #Since it is not i did not consider for now."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zdVHIgtGenb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\"calendar\" won't be used anymore. \n",
        "del calendar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaATj6-0Geke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\"daysBeforeEventTest\" will be used as input for predicting (We will forecast the days 1913-1941)\n",
        "daysBeforeEventTest = daysBeforeEvent[1913:1941]\n",
        "#\"daysBeforeEvent\" will be used for training as a feature.\n",
        "daysBeforeEvent = daysBeforeEvent[startDay:1913]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPpdPYtNGehT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Before concatanation with our main data \"dt\", indexes are made same and column name is changed to \"oneDayBeforeEvent\"\n",
        "daysBeforeEvent.columns = [\"oneDayBeforeEvent\"]\n",
        "daysBeforeEvent.index = dt.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu0YRo0fGrxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt = pd.concat([dt, daysBeforeEvent], axis = 1)\n",
        "\n",
        "dt.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzudu6vzGruV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature Scaling\n",
        "#Scale the features using min-max scaler in range 0-1\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "dt_scaled = sc.fit_transform(dt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHPCS-agGrrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(timesteps, 1913 - startDay):\n",
        "    X_train.append(dt_scaled[i-timesteps:i])\n",
        "    y_train.append(dt_scaled[i][0:30490]) \n",
        "    #Ä°mportant!! if extra features are added (like oneDayBeforeEvent) \n",
        "    #use only sales values for predictions (we only predict sales) \n",
        "    #this is why 0:30490 columns are choosen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctxip1GNGroA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del dt_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL5A7VDUGrlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert to np array to be able to feed the LSTM model\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8T27UwzG9W3",
        "colab_type": "text"
      },
      "source": [
        "## LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQJnOEwmG8UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Initialising the RNN\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "layer_1_units=50\n",
        "regressor.add(LSTM(units = layer_1_units, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "layer_2_units=400\n",
        "regressor.add(LSTM(units = layer_2_units, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "layer_3_units=400\n",
        "regressor.add(LSTM(units = layer_3_units))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding the output layer\n",
        "regressor.add(Dense(units = 30490))\n",
        "\n",
        "# Compiling the RNN\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "epoch_no=20\n",
        "batch_size_RNN=44\n",
        "regressor.fit(X_train, y_train, epochs = epoch_no, batch_size = batch_size_RNN)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9FV-hFYHBEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs= dt[-timesteps:]\n",
        "inputs = sc.transform(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_q_rj9RHBA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = []\n",
        "X_test.append(inputs[0:timesteps])\n",
        "X_test = np.array(X_test)\n",
        "predictions = []\n",
        "\n",
        "for j in range(timesteps,timesteps + 28):\n",
        "#X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "    predicted_stock_price = regressor.predict(X_test[0,j - timesteps:j].reshape(1, timesteps, 30491))\n",
        "    testInput = np.column_stack((np.array(predicted_stock_price), daysBeforeEventTest[0][1913 + j - timesteps]))\n",
        "    X_test = np.append(X_test, testInput).reshape(1,j + 1,30491)\n",
        "    predicted_stock_price = sc.inverse_transform(testInput)[:,0:30490]\n",
        "    predictions.append(predicted_stock_price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGSPORXLHQNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "submission = pd.DataFrame(data=np.array(predictions).reshape(28,30490))\n",
        "submission = submission.T\n",
        "submission = pd.concat((submission, submission), ignore_index=True)\n",
        "sample_submission = pd.read_csv(dataPath + \"/sample_submission.csv\")\n",
        "idColumn = sample_submission[[\"id\"]]\n",
        "submission[[\"id\"]] = idColumn  \n",
        "cols = list(submission.columns)\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "submission = submission[cols]\n",
        "colsdeneme = [\"id\"] + [f\"F{i}\" for i in range (1,29)]\n",
        "submission.columns = colsdeneme\n",
        "currentDateTime = time.strftime(\"%d%m%Y_%H%M%S\")\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}