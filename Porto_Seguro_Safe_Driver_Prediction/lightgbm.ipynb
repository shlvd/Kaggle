{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from path import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class Config:\n",
    "    input_path = Path('C:\\\\Users\\Lenovo\\Downloads\\porto-seguro-safe-driver-prediction')\n",
    "    optuna_lgb = False\n",
    "    n_estimators = 1500\n",
    "    early_stopping_round = 150\n",
    "    cv_folds = 5\n",
    "    random_state = 0\n",
    "    params = {'objective': 'binary',\n",
    "              'boosting_type': 'gbdt',\n",
    "              'learning_rate': 0.01,\n",
    "              'max_bin': 25,\n",
    "              'num_leaves': 31,\n",
    "              'min_child_samples': 1500,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'subsample_freq': 1,\n",
    "              'subsample': 0.7,\n",
    "              'reg_alpha': 1.0,\n",
    "              'reg_lambda': 1.0,\n",
    "              'verbosity': 0,\n",
    "              'random_state': 0}\n",
    "\n",
    "config = Config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.input_path / 'train.csv', index_col='id')\n",
    "test = pd.read_csv(config.input_path / 'test.csv', index_col='id')\n",
    "submission = pd.read_csv(config.input_path / 'sample_submission.csv', index_col='id')\n",
    "calc_features = [feat for feat in train.columns if \"_calc\" in feat]\n",
    "cat_features = [feat for feat in train.columns if \"_cat\" in feat]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "target = train[\"target\"]\n",
    "train = train.drop(\"target\", axis=\"columns\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train = train.drop(calc_features, axis=\"columns\")\n",
    "test = test.drop(calc_features, axis=\"columns\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=cat_features)\n",
    "test = pd.get_dummies(test, columns=cat_features)\n",
    "assert((train.columns==test.columns).all())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "@jit\n",
    "def eval_gini(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_pred)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "def gini_lgb(y_true, y_pred):\n",
    "    eval_name = 'normalized_gini_coef'\n",
    "    eval_result = eval_gini(y_true, y_pred)\n",
    "    is_higher_better = True\n",
    "    return eval_name, eval_result, is_higher_better"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "if config.optuna_lgb:\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 1.0),\n",
    "            'num_leaves': trial.suggest_int(\"num_leaves\", 3, 255),\n",
    "            'min_child_samples': trial.suggest_int(\"min_child_samples\",\n",
    "                                                   3, 3000),\n",
    "            'colsample_bytree': trial.suggest_float(\"colsample_bytree\",\n",
    "                                                    0.1, 1.0),\n",
    "            'subsample_freq': trial.suggest_int(\"subsample_freq\", 0, 10),\n",
    "            'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "            'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-9, 10.0),\n",
    "            'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-9, 10.0),\n",
    "        }\n",
    "\n",
    "        score = list()\n",
    "        skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True,\n",
    "                              random_state=config.random_state)\n",
    "        for train_idx, valid_idx in skf.split(train, target):\n",
    "            X_train = train.iloc[train_idx]\n",
    "            y_train = target.iloc[train_idx]\n",
    "            X_valid = train.iloc[valid_idx]\n",
    "            y_valid = target.iloc[valid_idx]\n",
    "            model = lgb.LGBMClassifier(**params,\n",
    "                                       n_estimators=1500,\n",
    "                                       early_stopping_round=150,\n",
    "                                       force_row_wise=True)\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=150,\n",
    "                                          verbose=False)]\n",
    "            model.fit(X_train, y_train,\n",
    "                      eval_set=[(X_valid, y_valid)],\n",
    "                      eval_metric=gini_lgb, callbacks=callbacks)\n",
    "\n",
    "            score.append(\n",
    "                model.best_score_['valid_0']['normalized_gini_coef'])\n",
    "        return np.mean(score)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=300)\n",
    "    print(\"Best Gini Normalized Score\", study.best_value)\n",
    "    print(\"Best parameters\", study.best_params)\n",
    "\n",
    "    params = {'objective': 'binary',\n",
    "              'boosting_type': 'gbdt',\n",
    "              'verbosity': 0,\n",
    "              'random_state': 0}\n",
    "\n",
    "    params.update(study.best_params)\n",
    "\n",
    "else:\n",
    "    params = config.params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = np.zeros(len(test))\n",
    "oof = np.zeros(len(train))\n",
    "metric_evaluations = list()\n",
    "skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, random_state=config.random_state)\n",
    "for idx, (train_idx, valid_idx) in enumerate(skf.split(train,\n",
    "                                                       target)):\n",
    "    print(f\"CV fold {idx}\")\n",
    "    X_train, y_train = train.iloc[train_idx], target.iloc[train_idx]\n",
    "    X_valid, y_valid = train.iloc[valid_idx], target.iloc[valid_idx]\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params,\n",
    "                               n_estimators=config.n_estimators,\n",
    "                               early_stopping_round=config.early_stopping_round,\n",
    "                               force_row_wise=True)\n",
    "\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=150),\n",
    "               lgb.log_evaluation(period=100, show_stdv=False)]\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_valid, y_valid)],\n",
    "              eval_metric=gini_lgb, callbacks=callbacks)\n",
    "    metric_evaluations.append(\n",
    "        model.best_score_['valid_0']['normalized_gini_coef'])\n",
    "    preds += (model.predict_proba(test,\n",
    "                                  num_iteration=model.best_iteration_)[:,1]\n",
    "              / skf.n_splits)\n",
    "    oof[valid_idx] = model.predict_proba(X_valid,\n",
    "                                         num_iteration=model.best_iteration_)[:,1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = np.zeros(len(test))\n",
    "oof = np.zeros(len(train))\n",
    "metric_evaluations = list()\n",
    "skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, random_state=config.random_state)\n",
    "for idx, (train_idx, valid_idx) in enumerate(skf.split(train,\n",
    "                                                       target)):\n",
    "    print(f\"CV fold {idx}\")\n",
    "    X_train, y_train = train.iloc[train_idx], target.iloc[train_idx]\n",
    "    X_valid, y_valid = train.iloc[valid_idx], target.iloc[valid_idx]\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params,\n",
    "                               n_estimators=config.n_estimators,\n",
    "                               early_stopping_round=config.early_stopping_round,\n",
    "                               force_row_wise=True)\n",
    "\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=150),\n",
    "               lgb.log_evaluation(period=100, show_stdv=False)]\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_valid, y_valid)],\n",
    "              eval_metric=gini_lgb, callbacks=callbacks)\n",
    "    metric_evaluations.append(\n",
    "        model.best_score_['valid_0']['normalized_gini_coef'])\n",
    "    preds += (model.predict_proba(test,\n",
    "                                  num_iteration=model.best_iteration_)[:,1]\n",
    "              / skf.n_splits)\n",
    "    oof[valid_idx] = model.predict_proba(X_valid,\n",
    "                                         num_iteration=model.best_iteration_)[:,1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"LightGBM CV normalized Gini coefficient: \\\n",
    "{np.mean(metric_evaluations):0.3f} \\\n",
    "({np.std(metric_evaluations):0.3f})\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission['target'] = preds\n",
    "submission.to_csv('lgb_submission.csv')\n",
    "oofs = pd.DataFrame({'id':train_index, 'target':oof})\n",
    "oofs.to_csv('dnn_oof.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}